{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSDS Homework 2\n",
    "\n",
    "Billy Nayden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages/helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import matplotlib as plt\n",
    "import os\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_lexical_diversity(*arg):\n",
    "    lexical_diversity = np.array([])\n",
    "    lexical_diversity_norm = np.array([])\n",
    "    \n",
    "    #### Getting the Lexical Diversity\n",
    "    for text in arg:\n",
    "        lexical_diversity = np.append(lexical_diversity,len(set(text)) / len(text))\n",
    "    \n",
    "    return (lexical_diversity)\n",
    "\n",
    "def percentage(count, total):\n",
    "    return 100 * count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_diversity = n_lexical_diversity(text1,text2,text3,text4,text5,text6,text7,text8,text9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Values by using sklearn\n",
      "- 0.07406285585022564\n",
      "- 0.04826383002768831\n",
      "- 0.06230453042623537\n",
      "- 0.06617622515804722\n",
      "- 0.13477005109975562\n",
      "- 0.1276595744680851\n",
      "- 0.12324685128531129\n",
      "- 0.22765564002465585\n",
      "- 0.0983485761345412\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalized Values by using sklearn\", *lexical_diversity,sep='\\n- ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_vocab_size(*arg):\n",
    "    vocab_size = np.array([])\n",
    "    vocab_size_norm = np.array([])\n",
    "    \n",
    "    #### Getting the Vocab Size\n",
    "    for text in arg:\n",
    "        vocab_size = np.append(vocab_size,len(set(text)))\n",
    "    \n",
    "    #### Normalizing using sklearn preprocessing \n",
    "    vocab_size_norm_sklearn = minmax_scale(vocab_size, feature_range=(0,1), axis=0)\n",
    "    \n",
    "    return(vocab_size_norm_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a function that looks at the length of the set of text in a particular corpus. I decided to use sklearn's MinMax scaler because I am familiar with it and know how it works. This ensures that the score is normalized between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = n_vocab_size(text1,text2,text3,text4,text5,text6,text7,text8,text9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates an array of the vocab size scores of all the various texts included in the `nltk.book` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Values by using sklearn\n",
      "- 0.9999999999999999\n",
      "- 0.3144049645779559\n",
      "- 0.09231698610577188\n",
      "- 0.48355208962600904\n",
      "- 0.2722829370091713\n",
      "- 0.05810313581196112\n",
      "- 0.6205722444944807\n",
      "- 0.0\n",
      "- 0.3129770992366412\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalized Values by using sklearn\", *vocab_size,sep='\\n- ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see the list of vocab sizes, normalized between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_long_words(*arg):\n",
    "    long_words = np.array([])\n",
    "    long_words_norm = np.array([])\n",
    "    \n",
    "    #### Getting the set of long words\n",
    "    words = [w for w in set(arg) if len(w) > 7]\n",
    "    for text in arg:\n",
    "        long_words = np.append(long_words,(len(set(words)))/len(set(text)))\n",
    "        \n",
    "    #### Normalizing using sklearn preprocessing \n",
    "    long_words_norm_sklearn = minmax_scale(long_words, feature_range=(0,1), axis=0)\n",
    "    \n",
    "    return(long_words_norm_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a function that looks at the number of long words in a particular corpus. I chose the cutoff for long words as words greater than 7 letters rather arbitrarily, because that was the example given in the ntlk book. I decided to use sklearn's MinMax scaler because I am familiar with it and know how it works. This ensures that the score is normalized between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_words = n_long_words(text1,text2,text3,text4,text5,text6,text7,text8,text9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates an array of the long words scores of all the various texts included in the `nltk.book` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Values by using sklearn\n",
      "- 0.0\n",
      "- 0.11117214975085979\n",
      "- 0.36059977748110617\n",
      "- 0.057724632774577025\n",
      "- 0.132922932046462\n",
      "- 0.48181981787643\n",
      "- 0.03388184663927429\n",
      "- 1.0\n",
      "- 0.11182920141704153\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalized Values by using sklearn\", *long_words,sep='\\n- ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see the list of long words scores, normalized between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt1 = open('Dramatic Reader for Lower Grades.txt')\n",
    "book1 = txt1.read()\n",
    "txt1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt2 = open('Sanders Union Fourth Reader.txt')\n",
    "book2 = txt2.read()\n",
    "txt2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt3 = open('Childrens Classics in Dramatic Form.txt')\n",
    "book3 = txt3.read()\n",
    "txt3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_text_difficulty_score(*arg):\n",
    "    text_difficulty_score = np.array([])\n",
    "    \n",
    "    for text in arg:\n",
    "        text_difficulty_score = n_lexical_diversity(text) + n_vocab_size(text) + n_long_words(text)\n",
    "    \n",
    "    return text_difficulty_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_difficulty_score = n_text_difficulty_score(book1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Difficulty Scores:\n",
      "- 0.0005524316859031272\n"
     ]
    }
   ],
   "source": [
    "print(\"Text Difficulty Scores:\", *text_difficulty_score,sep='\\n- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_difficulty_score = n_text_difficulty_score(book2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Difficulty Scores:\n",
      "- 0.00014217172548585316\n"
     ]
    }
   ],
   "source": [
    "print(\"Text Difficulty Scores:\", *text_difficulty_score,sep='\\n- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_difficulty_score = n_text_difficulty_score(book3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Difficulty Scores:\n",
      "- 0.0005297351932924564\n"
     ]
    }
   ],
   "source": [
    "print(\"Text Difficulty Scores:\", *text_difficulty_score,sep='\\n- ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet again, it appears that *Childrens Classics in Dramatic Form* and *Dramatic Reader for Lower Grades* ae similar in terms of difficulty scores, while *Sanders Union Fourth Reader* appears to be the least difficult with this new metric. I believe that this difficulty score is more useful than the one in Homework 1 because it takes into account longer words, which tend to be more difficult to read, and the raw size of the vocabulary, in addition to the lexical diversity. Additionally, normalizing the scores makes it easier to read.\n",
    "\n",
    "I will admit I had some trouble creating an array that would produce all the scores at once, and believe it has to do with reading in these txt files as strings, so I would love to cover that in a future live session."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
