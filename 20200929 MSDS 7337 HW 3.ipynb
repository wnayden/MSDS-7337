{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Billy Nayden\n",
    "## Homework 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\WilliamNayden\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import nltk\n",
    "from nltk.metrics import *\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "import pprint\n",
    "from difflib import SequenceMatcher\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\tCompare your given name with your nickname (if you donâ€™t have a nickname, invent one for this assignment) by answering the following questions:\n",
    "    a.\tWhat is the edit distance between your nickname and your given name?\n",
    "    b.\tWhat is the percentage string match between your nickname and your given name?\n",
    "Show your work for both calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The edit distance from my name to my nickname is 4.\n"
     ]
    }
   ],
   "source": [
    "name = 'William'\n",
    "nickname = 'Billy'\n",
    "\n",
    "#Using edit_distance metric from nltk.metrics\n",
    "distance = edit_distance(name, nickname)\n",
    "print(\"The edit distance from my name to my nickname is {}.\".format(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage string match between my nickname and name is 50.0%.\n"
     ]
    }
   ],
   "source": [
    "#using SequenceMatcher from difflib\n",
    "#https://docs.python.org/3/library/difflib.html#difflib.SequenceMatcher\n",
    "string_match = SequenceMatcher(None, nickname, name)\n",
    "print(\"The percentage string match between my nickname and name is {}%.\".format(round(string_match.ratio()*100, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\tFind a friend (or family member or classmate) who you know has read a certain book. Without your friend knowing, copy the first two sentences of that book. Now rewrite the words from those sentences, excluding stop words. Now tell your friend to guess which book the words are from by reading them just that list of words. Did you friend correctly guess the book on the first try? What did he or she guess? Explain why you think you friend either was or was not able to guess the book from hearing the list of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book: The Vanishing Half by Brit Bennett\n",
      "\n",
      "Originial sentence:\n",
      " The morning one of the lost twins returned to Mallard, Lou LeBon ran to the diner to break the news and even now, many years later, everyone remembers the shock of sweaty Lou pushing through the glass doors, chest heaving, neckline darkened with his own effort. \n",
      "\n",
      "Sentence without stopwords:\n",
      " The morning lost twins returned Mallard , Lou LeBon ran diner break news even , many years later , everyone remembers shock sweaty Lou pushing glass doors , chest heaving , neckline darkened effort .\n"
     ]
    }
   ],
   "source": [
    "#https://stackabuse.com/removing-stop-words-from-strings-in-python/#:~:text=Using%20Python's%20NLTK%20Library&text=NLTK%20supports%20stop%20word%20removal,stop%20words%20provided%20by%20NLTK.\n",
    "\n",
    "first_sents = \"The morning one of the lost twins returned to Mallard, Lou LeBon ran to the diner to break the news and even now, many years later, everyone remembers the shock of sweaty Lou pushing through the glass doors, chest heaving, neckline darkened with his own effort.\"\n",
    "\n",
    "vanishinghalf_tkized = word_tokenize(first_sents) #Tokenized text\n",
    "vanishinghalf_tkized_nsw = [x for x in vanishinghalf_tkized if x not in stopwords.words()] #Stop words removed\n",
    "vanishinghalf_reconstructed = \" \".join(vanishinghalf_tkized_nsw)\n",
    "print(\"Book: The Vanishing Half by Brit Bennett\\n\")\n",
    "print(\"Originial sentence:\\n\", first_sents, \"\\n\")\n",
    "print(\"Sentence without stopwords:\\n\", vanishinghalf_reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The book I chose is *The Vanishing Half* by Brit Bennett, which my wife is currently reading. Because the first sentence is so long, I thought it was sufficient to analyze. My wife was able to recognize it immediately because of the use of \"twins\" and \"Mallard\" which is a central plot point in the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\tRun one of the stemmers available in Python. Run the same two sentences from question 2 above through the stemmer and show the results. How many of the outputted stems are valid morphological roots of the corresponding words? Express this answer as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence:\n",
      " The morning one of the lost twins returned to Mallard Lou LeBon ran to the diner to break the news and even now many years later everyone remembers the shock of sweaty Lou pushing through the glass doors chest heaving neckline darkened with his own effort \n",
      "\n",
      "Stemmed sentences:\n",
      " the morn one of the lost twin return to mallard lou lebon ran to the diner to break the news and even now mani year later everyon rememb the shock of sweati lou push through the glass door chest heav necklin darken with hi own effort \n",
      "\n",
      "\n",
      "The percentage of valid morpholigical roots from stemmed words is: 28.57 %\n"
     ]
    }
   ],
   "source": [
    "#Porter Stemmer\n",
    "#https://www.nltk.org/howto/stem.html\n",
    "#https://stackoverflow.com/questions/53664775/how-to-remove-punctuation-in-python\n",
    "\n",
    "p_stem = PorterStemmer()\n",
    "punc= \".,\"\n",
    "import string\n",
    "\n",
    "#Put everything in lowercase\n",
    "#first_sents = first_sents.lower()\n",
    "\n",
    "#Remove punctuation for stemmer\n",
    "for i in first_sents:\n",
    "    for j in punc:\n",
    "        if i in punc:\n",
    "            first_sents = first_sents.replace(i, \"\")\n",
    "            \n",
    "#Put sentence into a list for stemmer\n",
    "first_sents_list = first_sents.split()\n",
    "\n",
    "#Apply stemmer\n",
    "stemmed = [p_stem.stem(x) for x in first_sents_list]\n",
    "\n",
    "#Reconstruct sentence\n",
    "stemmed_reconstrcuted = \" \".join(stemmed)\n",
    "\n",
    "print(\"Original sentence:\\n\", first_sents, \"\\n\")\n",
    "print(\"Stemmed sentences:\\n\", stemmed_reconstrcuted, \"\\n\\n\")\n",
    "\n",
    "#Valid morpholigical roots\n",
    "words_stemmed = 7 #7 Words were stemmed\n",
    "valid_roots = 2 #2 are valid mophological roots\n",
    "\n",
    "print(\"The percentage of valid morpholigical roots from stemmed words is:\", round((valid_roots/words_stemmed)*100,2), \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
