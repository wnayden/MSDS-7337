{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 8\n",
    "Billy Nayden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import textblob\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "np.set_printoptions(precision=2, linewidth=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in spreadsheet with links\n",
    "df = pd.read_excel('C:\\\\Users\\\\WilliamNayden\\\\Documents\\\\MSDS\\\\20201019_IMDB_Reviews_for_NLP.xlsx')\n",
    "\n",
    "link_list = df['Link'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. In Python, load one of the sentiment vocabularies referenced in the textbook, and run the sentiment analyzer as explained in the corresponding reference. Add words to the sentiment vocabulary, if you think you need to, to better fit your particular text collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up to remove stopwords\n",
    "new_stops = list(stopwords.words('english'))\n",
    "\n",
    "new_stops = new_stops + ['show', 'it', 'get', ' it.', 'it\\'s', 'series', 'season', \n",
    "                         'can', 've', 'watch', 'watched', 'much', 'lot', 'thus', 'no', 'need', 'needed', 'should\\'ve',\n",
    "                        'it,', 'can.', 'can,']\n",
    "stop_words = new_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append reviews to a list\n",
    "\n",
    "output = []\n",
    "\n",
    "#Append reviews to a list\n",
    "\n",
    "for i in link_list[9:109]:\n",
    "    lst = []\n",
    "    \n",
    "    #Parse HTML\n",
    "    page = requests.get(i)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    #Pull out data we need\n",
    "    span = str(soup.find('div', attrs={'text show-more__control'}).text).strip()\n",
    "    for i in span.split(' '):\n",
    "            if i not in stop_words:\n",
    "                lst.append(i)\n",
    "    \n",
    "    #Turn Reviews into List\n",
    "    span_nostop = ' '.join(lst)\n",
    "    \n",
    "    output.append(str(span_nostop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This feel like Star Wars. Now, I know people said viewing The Phantom Menace, prequels, despite flaws, delivered picture larger complex galaxy one introduced original trilogy. The prequel characters poorly written, scene direction felt times, Jar Jar existed, end day I'll take prequels new Disney films painted universe. They made want see Star Wars, I appreciated original trilogy's story arc even watching them. The Last Jedi complete opposite. It killed interest Star Wars universe seems nothing left care about. The Resistance Rebels. The First Order Empire. No end sight. Rey perfect already. Snoke dead one cared enough even explain existence first place. The original trilogy might well never happened. We've three death stars. No stable political structure seems possible galaxy, visit films. For know conflict could taking place one tiny sector galaxy rest galaxy completely loop. Sure, people space casino make money selling weapons slave kid Rebellion ring now, that's enough establish I care story anymore. \"They blow today, blow tomorrow.\"The humor cringe-worthy. Even characters care. Poe's prank-call beginning dissolved anxiety might feel character right gate. Star Wars take seriously 100% time, characters feel like they're fighting real battles. I even want talk casino scenes. Disney right lecture us capitalism. Much movie scenes lifted The Empire Strikes Back Return Jedi, cut-and-pasted around different order figure out. I sense tone disrespect viewers' intelligence. Additionally, deeply disturbing see critics give movie high rating see news outlets publish articles questioning seriously take backlash. It flaw ratings system. Sure, casual young viewers enjoy. But backlash real, crusty old fanboys nostalgic good ol' days complaining political agendas (not fanboys always illegitimate arguments). I'm twenty-two year old woman I disappointed. Star Wars everyone. That include fans, people love good stories.\n"
     ]
    }
   ],
   "source": [
    "#Check output\n",
    "print (output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get polarity score\n",
    "sentiment_polarity = [textblob.TextBlob(review).sentiment.polarity for review in output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorize as positive or negative\n",
    "sentiment_category = ['positive' if score >= 0.1  else 'negative' for score in sentiment_polarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                Review  Polarity  Category\n",
       "0   I dont understand fan base anymore, people lik...  0.217686  positive\n",
       "1   This feel like Star Wars. Now, I know people s...  0.086726  negative\n",
       "2   The Last Jedi obsessed fallacious idea order m... -0.011543  negative\n",
       "3   I relatively high expectations Episode VIII. U...  0.073099  negative\n",
       "4   I hate TLJ, even I completely ignore (among ma...  0.045661  negative\n",
       "..                                                ...       ...       ...\n",
       "91  This movie, hyped movie time, put microscope l...  0.156279  positive\n",
       "92  Well, waiting 16 years next installment,  Geor...  0.123223  positive\n",
       "93  This movie begins back story anakin skywalker ...  0.232143  positive\n",
       "94  I know fashionable scorn \"prequel\" trilogy, on...  0.177969  positive\n",
       "95  The main line defence seems be: lighten up, en...  0.053697  negative\n",
       "\n",
       "[96 rows x 3 columns]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to dataframe\n",
    "df = pd.DataFrame(list(zip(output, sentiment_polarity, sentiment_category)),\n",
    "              columns=['Review','Polarity', 'Category'])\n",
    "\n",
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\tFor each of the clusters you created in homework 7, compute the average, median, high, and low sentiment scores for each cluster. Explain whether you think this reveals anything interesting about the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words={'english'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform tf-idf on reviews\n",
    "links_vect = vectorizer.fit_transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 4800)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at shape\n",
    "links_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "#https://scikit-learn.org/stable/modules/clustering.html#k-means\n",
    "#https://matplotlib.org/tutorials/introductory/pyplot.html\n",
    "#################################inertia_ is the sum of squared distance from cluster center#################################\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt #import matplotlib to examine intracluster distnaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster: 0\n",
      "many\n",
      "still\n",
      "aspects\n",
      "scrolling\n",
      "heck\n",
      "user\n",
      "seen\n",
      "stated\n",
      "occasional\n",
      "average\n",
      "cluster: 1\n",
      "anakin\n",
      "the\n",
      "movie\n",
      "clones\n",
      "wars\n",
      "episode\n",
      "attack\n",
      "star\n",
      "story\n",
      "lucas\n",
      "cluster: 2\n",
      "movie\n",
      "jar\n",
      "the\n",
      "good\n",
      "ok\n",
      "is\n",
      "four\n",
      "age\n",
      "kid\n",
      "talks\n",
      "cluster: 3\n",
      "movies\n",
      "movie\n",
      "star\n",
      "wars\n",
      "the\n",
      "it\n",
      "fan\n",
      "original\n",
      "liked\n",
      "like\n",
      "cluster: 4\n",
      "even\n",
      "good\n",
      "bad\n",
      "the\n",
      "still\n",
      "cgi\n",
      "best\n",
      "movie\n",
      "film\n",
      "worst\n",
      "cluster: 5\n",
      "the\n",
      "film\n",
      "star\n",
      "and\n",
      "force\n",
      "it\n",
      "rey\n",
      "they\n",
      "movie\n",
      "luke\n",
      "cluster: 6\n",
      "luke\n",
      "film\n",
      "the\n",
      "star\n",
      "wars\n",
      "this\n",
      "empire\n",
      "battle\n",
      "one\n",
      "love\n"
     ]
    }
   ],
   "source": [
    "#Examine 7 Clusters\n",
    "kmeans = KMeans(n_clusters=7, random_state=11)\n",
    "clustered = kmeans.fit(links_vect)\n",
    "clustered.labels_\n",
    "#https://pythonprogramminglanguage.com/kmeans-text-clustering/\n",
    "\n",
    "#Print top words of each cluster\n",
    "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "words = vectorizer.get_feature_names()\n",
    "for i in range(7):\n",
    "    print(\"cluster:\", i)\n",
    "    for j in order_centroids[i, :10]:\n",
    "        print(words[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96,)\n"
     ]
    }
   ],
   "source": [
    "#Check shape of cluster labels\n",
    "print(clustered.labels_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                Review  Polarity  Category  \\\n",
       "0   I dont understand fan base anymore, people lik...  0.217686  positive   \n",
       "1   This feel like Star Wars. Now, I know people s...  0.086726  negative   \n",
       "2   The Last Jedi obsessed fallacious idea order m... -0.011543  negative   \n",
       "3   I relatively high expectations Episode VIII. U...  0.073099  negative   \n",
       "4   I hate TLJ, even I completely ignore (among ma...  0.045661  negative   \n",
       "..                                                ...       ...       ...   \n",
       "91  This movie, hyped movie time, put microscope l...  0.156279  positive   \n",
       "92  Well, waiting 16 years next installment,  Geor...  0.123223  positive   \n",
       "93  This movie begins back story anakin skywalker ...  0.232143  positive   \n",
       "94  I know fashionable scorn \"prequel\" trilogy, on...  0.177969  positive   \n",
       "95  The main line defence seems be: lighten up, en...  0.053697  negative   \n",
       "\n",
       "    Cluster  \n",
       "0         3  \n",
       "1         5  \n",
       "2         5  \n",
       "3         5  \n",
       "4         5  \n",
       "..      ...  \n",
       "91        2  \n",
       "92        5  \n",
       "93        1  \n",
       "94        5  \n",
       "95        2  \n",
       "\n",
       "[96 rows x 4 columns]>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Append cluster labels to dataframe\n",
    "cluster_labels = clustered.labels_\n",
    "\n",
    "df['Cluster'] = cluster_labels\n",
    "\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.067860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.136171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.038538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.180502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.124627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.076720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.242628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster  Polarity\n",
       "0        0  0.067860\n",
       "1        1  0.136171\n",
       "2        2  0.038538\n",
       "3        3  0.180502\n",
       "4        4  0.124627\n",
       "5        5  0.076720\n",
       "6        6  0.242628"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute mean polarity values\n",
    "df.groupby('Cluster', as_index=False)['Polarity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.242857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.138676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.053697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.202527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.145588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.074191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.200558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster  Polarity\n",
       "0        0  0.242857\n",
       "1        1  0.138676\n",
       "2        2  0.053697\n",
       "3        3  0.202527\n",
       "4        4  0.145588\n",
       "5        5  0.074191\n",
       "6        6  0.200558"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute median polarity values\n",
    "df.groupby('Cluster', as_index=False)['Polarity'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.344056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.412188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.156279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.587946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster  Polarity\n",
       "0        0  0.344056\n",
       "1        1  0.412188\n",
       "2        2  0.156279\n",
       "3        3  0.587946\n",
       "4        4  1.000000\n",
       "5        5  0.500000\n",
       "6        6  1.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute max polarity values\n",
    "df.groupby('Cluster', as_index=False)['Polarity'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.169318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.152885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.404830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.388095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.350000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster  Polarity\n",
       "0        0 -0.383333\n",
       "1        1 -0.169318\n",
       "2        2 -0.152885\n",
       "3        3 -0.404830\n",
       "4        4 -0.766667\n",
       "5        5 -0.388095\n",
       "6        6 -0.350000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute min polarity values\n",
    "df.groupby('Cluster', as_index=False)['Polarity'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think what's interesting is most of these reviews have positive polarity scores, indicating that many people enjoy Star Wars. I would be interested in viewing these scores by movie, using human created categories, rather the the clusters utilized here. I would imagine that the newer trilogies would have many more negative reviews than the original trilogies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\tFor extra credit, analyze sentiment of chunks as follows:\n",
    "   > a.\tTake the chunks from homework 5, and in Python, run each chunk individually through your sentiment analyzer that you used in question 1. If the chunk registers a nonneutral sentiment, save it in a tabular format (the chunk, the sentiment score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NP Chunker from HW5\n",
    "\n",
    "output = {}\n",
    "counter = 1\n",
    "\n",
    "np_rule = \"NP: {<DT>?<JJ.*>*<NN.*>+}\"\n",
    "np = nltk.RegexpParser(np_rule)\n",
    "\n",
    "for i in link_list[9:109]:\n",
    "    lst = []\n",
    "    page = requests.get(i)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    span = str(soup.find('div', attrs={'text show-more__control'}).text).strip()\n",
    "    tokenized = word_tokenize(span)\n",
    "    tagged = nltk.pos_tag(tokenized)\n",
    "    chunked = np.parse(tagged)\n",
    "    for subtree in chunked.subtrees():\n",
    "        if subtree.label() == 'NP':\n",
    "            lst.append(subtree)\n",
    "    \n",
    "    output[\"Review: \" + str(counter)] = lst\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an array of the chuncks\n",
    "chunk_list = []\n",
    "for k,v in output.items():\n",
    "    chunk_list.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list we can extract the words from\n",
    "chunks = []\n",
    "for i in chunk_list:\n",
    "    for j in i:\n",
    "        chunks.append(j[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get words from chunks\n",
    "tmp = []\n",
    "for i in chunks:\n",
    "    for j in i:\n",
    "        tmp.append(j)\n",
    "\n",
    "#List of just the words\n",
    "words = tmp[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get polarity scores\n",
    "chunk_sent = []\n",
    "for i in words:\n",
    "    \n",
    "    #Blob it\n",
    "    blob = textblob.TextBlob(i)\n",
    "\n",
    "    #Sentiment Analysis - this funciton removes punctuation and tokenizes \n",
    "    sent = blob.sentiment\n",
    "\n",
    "    #add to sentiment list\n",
    "    chunk_sent.append(sent.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7956\n",
      "7956\n"
     ]
    }
   ],
   "source": [
    "#ensure the chunks and polarity scores are the same length\n",
    "print(len(chunk_sent))\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_sent_table = pd.DataFrame({'Chunk': chunks, 'Sentiment Score': chunk_sent})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment/Chunk Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chunk</th>\n",
       "      <th>Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(the, DT)</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(most, JJS)</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Force, NNP)</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(everyone, NN)</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Rogue, NNP)</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7951</th>\n",
       "      <td>(Walt, NNP)</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7952</th>\n",
       "      <td>(THAT, NNP)</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7953</th>\n",
       "      <td>(Never, NN)</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7954</th>\n",
       "      <td>(much, JJ)</td>\n",
       "      <td>0.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7955</th>\n",
       "      <td>(little, JJ)</td>\n",
       "      <td>-0.1875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7956 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Chunk  Sentiment Score\n",
       "0          (the, DT)           0.0000\n",
       "1        (most, JJS)           0.5000\n",
       "2       (Force, NNP)           0.0000\n",
       "3     (everyone, NN)           0.0000\n",
       "4       (Rogue, NNP)           0.0000\n",
       "...              ...              ...\n",
       "7951     (Walt, NNP)           0.0000\n",
       "7952     (THAT, NNP)           0.0000\n",
       "7953     (Never, NN)           0.0000\n",
       "7954      (much, JJ)           0.2000\n",
       "7955    (little, JJ)          -0.1875\n",
       "\n",
       "[7956 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_sent_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b. Now sort the table twice, once to show the highest negative-sentiment-scoring chunks at the top and again to show the highest positive-sentiment-scoring chunks at the top. Examine the upper portions of both sorted lists, to identify any trends, and explain what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chunk</th>\n",
       "      <th>Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5055</th>\n",
       "      <td>(excellent, JJ)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>(delicious, JJ)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5801</th>\n",
       "      <td>(Excellent, JJ)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3855</th>\n",
       "      <td>(wonderful, JJ)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>(best, JJS)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>(superb, NN)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914</th>\n",
       "      <td>(perfect, JJ)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>(Legendary, JJ)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>(flawless, NN)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6150</th>\n",
       "      <td>(Flawless, NNP)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3671</th>\n",
       "      <td>(greatest, JJS)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>(breathtaking, NN)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>(brilliant, NN)</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7294</th>\n",
       "      <td>(brilliant, JJ)</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>(beautiful, JJ)</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>(Beautiful, NNP)</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>(fly, NN)</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>(great, JJ)</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>(proud, NNS)</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3585</th>\n",
       "      <td>(joy, NN)</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>(Great, NNP)</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>(brave, NN)</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6860</th>\n",
       "      <td>(brave, JJ)</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>(successful, JJ)</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>(good, JJ)</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7881</th>\n",
       "      <td>(Good, JJ)</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7704</th>\n",
       "      <td>(surprising, JJ)</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7734</th>\n",
       "      <td>(heroic, NN)</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3767</th>\n",
       "      <td>(fascinating, JJ)</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6877</th>\n",
       "      <td>(exceptional, JJ)</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>(amazing, JJ)</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>(effective, JJ)</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>(kind, NN)</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>(Rose, NNP)</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6883</th>\n",
       "      <td>(own, JJ)</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>(spectacular, JJ)</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>(imaginative, JJ)</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4647</th>\n",
       "      <td>(popular, JJ)</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>(warm, JJ)</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>(deserving, NN)</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Chunk  Sentiment Score\n",
       "5055     (excellent, JJ)         1.000000\n",
       "251      (delicious, JJ)         1.000000\n",
       "5801     (Excellent, JJ)         1.000000\n",
       "3855     (wonderful, JJ)         1.000000\n",
       "2992         (best, JJS)         1.000000\n",
       "2928        (superb, NN)         1.000000\n",
       "4914       (perfect, JJ)         1.000000\n",
       "2091     (Legendary, JJ)         1.000000\n",
       "1703      (flawless, NN)         1.000000\n",
       "6150     (Flawless, NNP)         1.000000\n",
       "3671     (greatest, JJS)         1.000000\n",
       "1709  (breathtaking, NN)         1.000000\n",
       "7211     (brilliant, NN)         0.900000\n",
       "7294     (brilliant, JJ)         0.900000\n",
       "4560     (beautiful, JJ)         0.850000\n",
       "5289    (Beautiful, NNP)         0.850000\n",
       "261            (fly, NN)         0.800000\n",
       "3841         (great, JJ)         0.800000\n",
       "7495        (proud, NNS)         0.800000\n",
       "3585           (joy, NN)         0.800000\n",
       "1582        (Great, NNP)         0.800000\n",
       "1310         (brave, NN)         0.800000\n",
       "6860         (brave, JJ)         0.800000\n",
       "3517    (successful, JJ)         0.750000\n",
       "4268          (good, JJ)         0.700000\n",
       "7881          (Good, JJ)         0.700000\n",
       "7704    (surprising, JJ)         0.700000\n",
       "7734        (heroic, NN)         0.700000\n",
       "3767   (fascinating, JJ)         0.700000\n",
       "6877   (exceptional, JJ)         0.666667\n",
       "2476       (amazing, JJ)         0.600000\n",
       "425      (effective, JJ)         0.600000\n",
       "1689          (kind, NN)         0.600000\n",
       "519          (Rose, NNP)         0.600000\n",
       "6883           (own, JJ)         0.600000\n",
       "4729   (spectacular, JJ)         0.600000\n",
       "3372   (imaginative, JJ)         0.600000\n",
       "4647       (popular, JJ)         0.600000\n",
       "3267          (warm, JJ)         0.600000\n",
       "3633     (deserving, NN)         0.600000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort by highest sentiment score\n",
    "cst_top = chunk_sent_table.sort_values(by='Sentiment Score', ascending=False).drop_duplicates()\n",
    "\n",
    "cst_top.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chunk</th>\n",
       "      <th>Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>(terrible, JJ)</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>(evil, JJ)</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>(cruel, JJ)</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>(evil, NN)</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>(insulting, JJ)</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>(boring, JJ)</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6966</th>\n",
       "      <td>(menacing, JJ)</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>(awful, JJ)</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>(pathetic, JJ)</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4026</th>\n",
       "      <td>(Worst, NNP)</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4359</th>\n",
       "      <td>(evil, NNS)</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>(crap, NN)</td>\n",
       "      <td>-0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>(hate, JJ)</td>\n",
       "      <td>-0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5139</th>\n",
       "      <td>(Grievous, NNP)</td>\n",
       "      <td>-0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4484</th>\n",
       "      <td>(tragic, JJ)</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>(anger, NN)</td>\n",
       "      <td>-0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>(atrocious, JJ)</td>\n",
       "      <td>-0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7777</th>\n",
       "      <td>(merciless, JJ)</td>\n",
       "      <td>-0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5777</th>\n",
       "      <td>(bad, JJ)</td>\n",
       "      <td>-0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>(Bad, NNP)</td>\n",
       "      <td>-0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5629</th>\n",
       "      <td>(crazy, JJ)</td>\n",
       "      <td>-0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>(awkward, NN)</td>\n",
       "      <td>-0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>(dirty, JJ)</td>\n",
       "      <td>-0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6813</th>\n",
       "      <td>(coldly, JJ)</td>\n",
       "      <td>-0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>(scathing, JJ)</td>\n",
       "      <td>-0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>(meaningless, JJ)</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>(needless, JJ)</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7317</th>\n",
       "      <td>(silly, JJ)</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6027</th>\n",
       "      <td>(unfair, JJ)</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7037</th>\n",
       "      <td>(weird, NN)</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382</th>\n",
       "      <td>(sad, NN)</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6519</th>\n",
       "      <td>(Lame, NNP)</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5781</th>\n",
       "      <td>(creepy, NN)</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>(vague, NN)</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5614</th>\n",
       "      <td>(angry, JJ)</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>(sinister, NN)</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>(lame, JJ)</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902</th>\n",
       "      <td>(cheesy, JJ)</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>(weird, JJ)</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7904</th>\n",
       "      <td>(fail, NN)</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Chunk  Sentiment Score\n",
       "903      (terrible, JJ)            -1.00\n",
       "6484         (evil, JJ)            -1.00\n",
       "460         (cruel, JJ)            -1.00\n",
       "3241         (evil, NN)            -1.00\n",
       "2248    (insulting, JJ)            -1.00\n",
       "3085       (boring, JJ)            -1.00\n",
       "6966     (menacing, JJ)            -1.00\n",
       "4746        (awful, JJ)            -1.00\n",
       "266      (pathetic, JJ)            -1.00\n",
       "4026       (Worst, NNP)            -1.00\n",
       "4359        (evil, NNS)            -1.00\n",
       "1687         (crap, NN)            -0.80\n",
       "1496         (hate, JJ)            -0.80\n",
       "5139    (Grievous, NNP)            -0.80\n",
       "4484       (tragic, JJ)            -0.75\n",
       "4294        (anger, NN)            -0.70\n",
       "3068    (atrocious, JJ)            -0.70\n",
       "7777    (merciless, JJ)            -0.70\n",
       "5777          (bad, JJ)            -0.70\n",
       "1454         (Bad, NNP)            -0.70\n",
       "5629        (crazy, JJ)            -0.60\n",
       "271       (awkward, NN)            -0.60\n",
       "513         (dirty, JJ)            -0.60\n",
       "6813       (coldly, JJ)            -0.60\n",
       "5464     (scathing, JJ)            -0.60\n",
       "6491  (meaningless, JJ)            -0.50\n",
       "2710     (needless, JJ)            -0.50\n",
       "7317        (silly, JJ)            -0.50\n",
       "6027       (unfair, JJ)            -0.50\n",
       "7037        (weird, NN)            -0.50\n",
       "4382          (sad, NN)            -0.50\n",
       "6519        (Lame, NNP)            -0.50\n",
       "5781       (creepy, NN)            -0.50\n",
       "6704        (vague, NN)            -0.50\n",
       "5614        (angry, JJ)            -0.50\n",
       "7183     (sinister, NN)            -0.50\n",
       "1462         (lame, JJ)            -0.50\n",
       "3902       (cheesy, JJ)            -0.50\n",
       "931         (weird, JJ)            -0.50\n",
       "7904         (fail, NN)            -0.50"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort by lowest sentiment score\n",
    "cst_low = chunk_sent_table.sort_values(by='Sentiment Score', ascending=True).drop_duplicates()\n",
    "cst_low.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part these sentiment scores make sense, but I think some of the proper nouns and character names in the reviews confuse the algorithm a bit. For example, the term \"Rose\" has one of the highest sentiment scores of any term, but refers to a character from the third Star Wars trilogy. Similarly \"Grevious\" has a very low sentiment score, but refers to General Greivous, a villain in the prequal trilogies. WHile both of these characters posses nomenclatures that reflect whether they are \"good\" or \"bad\" in the Star Wars universe, I find it interesting that this shows up in sentiment analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
